{
  "session": 108,
  "updated": "2026-02-12T05:30:00Z",
  "agent_version": "1.0.70",
  "iso_version": "installer-v8-dialog-tui",
  "disk_image_version": "v56",
  "system_health": {
    "vps_api": "healthy",
    "dashboard": "healthy",
    "physical_appliance": "v1.0.70_heal_priority_chaos_fixes",
    "vm_appliance": "v1.0.70_heal_priority_chaos_fixes",
    "redis_minio": "localhost_only",
    "minio_worm": "evidence-worm-v2_compliance_90d_object_lock",
    "learning_flywheel": "active_22_promoted_stats_fixed_cicd_deploying",
    "incident_resolution": "pipeline_active",
    "evidence_pipeline": "end_to_end_live_182k_bundles_all_signed_worm_active",
    "compliance_packets": "live_endpoint_real_data_deployed_to_vps",
    "ots_proofs": "2705_anchored_251_pending_78699_expired_background_drain_active",
    "fleet_updates": "proven_end_to_end_overlay_plus_nixos_rebuild"
  },
  "current_blocker": "None - evidence pipeline end-to-end operational",
  "architecture_decision": {
    "approach": "Golden flake + nixos-install",
    "rationale": "DD disk images cause hardware-specific failures (ESP timeouts, firmware mismatches). nixos-install from flake works on any x86_64 hardware.",
    "key_files": [
      "iso/appliance-image.nix (installer ISO with dialog TUI + msp-auto-install)",
      "iso/appliance-disk-image.nix (installed system config)",
      "iso/configuration.nix (base appliance config)",
      "flake.nix (nixosConfigurations.appliance)"
    ]
  },
  "fleet_update_mechanism": {
    "overlay_flow": [
      "1. Insert update_agent order with tarball URL",
      "2. Agent downloads tarball, extracts to /var/lib/msp/agent-overlay/",
      "3. Agent restarts via systemctl restart",
      "4. _apply_overlay() detects overlay, purges modules, re-imports from overlay",
      "5. Agent runs with overlay code (new handlers, fixes, etc.)",
      "NOTE: Pre-fix appliances use argparse.py bootstrap shim to activate overlay"
    ],
    "rebuild_flow": [
      "1. Insert nixos_rebuild order with flake_ref",
      "2. Agent runs nixos-rebuild test via systemd-run (escapes ProtectSystem sandbox)",
      "3. New system activates, agent restarts with new nix code",
      "4. _verify_rebuild_if_pending() writes .rebuild-verified",
      "5. Watchdog timer persists rebuild with nixos-rebuild switch",
      "6. If agent fails to check in within 10 min, watchdog rolls back"
    ],
    "key_insight": "NixOS buildPythonApplication wrappers override PYTHONPATH, making os.execve useless for overlay activation. Fix: purge sys.modules + update __path__ within same process. Pre-fix bootstrap: fake argparse.py intercepts first import in main().",
    "overlay_structure": "CRITICAL: Tarball must create compliance_agent/ subdirectory. Build: mkdir -p overlay/compliance_agent && cp -R src/compliance_agent/* overlay/compliance_agent/ && cp VERSION overlay/"
  },
  "active_tasks": [
    {
      "id": 2,
      "task": "Rotate leaked credentials from old settings.local.json",
      "status": "completed",
      "priority": "high",
      "note": "Infra rotated: PostgreSQL, Redis, MinIO, session/API secrets. Fixed hardcoded REDIS_URL bug in docker-compose.yml. External pending: Anthropic API key, AWS keys (AKIA2J4U2R6VFUUEUKXD), SMTP, Microsoft/Google OAuth secrets \u2014 user must rotate at provider consoles."
    },
    {
      "id": 6,
      "task": "Create migration 036_credential_versioning.sql",
      "status": "completed",
      "note": "Already existed at mcp-server/central-command/backend/migrations/036_credential_versioning.sql"
    },
    {
      "id": 9,
      "task": "Old evidence-worm bucket cleanup",
      "status": "in_progress",
      "note": "rm -rf running on VPS (PID 3841089) against /mnt/storagebox. Slow due to network-mounted CIFS. Will finish on its own"
    },
    {
      "id": 10,
      "task": "Re-submit expired OTS proofs",
      "status": "completed",
      "note": "Added _ots_resubmit_expired_loop() background task in main.py. Runs on server startup, drains 78K expired proofs in 500-proof batches with 30s delays. Backs off to 5min on calendar failures, stops after 5 consecutive zero-success batches. Also set last_upgrade_attempt on failed resubmissions to prevent tight retry loops."
    },
    {
      "id": 11,
      "task": "Fix Bitcoin block height extraction in OTS",
      "status": "completed",
      "priority": "low",
      "note": "Fixed: replaced fixed 4-byte int with read_bitcoin_varint(). Commit e60bdfa"
    },
    {
      "id": 15,
      "task": "Fix rebuild order completion on agent restart",
      "status": "completed",
      "priority": "medium",
      "note": "Persists order_id to /var/lib/msp/.pending-rebuild-order before rebuild. Completes on first successful checkin after restart. Commit 9e3d408."
    },
    {
      "id": 16,
      "task": "Add healing order handler",
      "status": "completed",
      "priority": "medium",
      "note": "Added 'healing' to dispatch dict + _handle_healing() routes through _execute_healing_action() with run_runbook:<ID> format. Commit 9e3d408."
    },
    {
      "id": 18,
      "task": "Finish Linux VM SSH + chaos integration",
      "status": "completed",
      "priority": "high",
      "note": "DONE: Root cause was empty /root/.ssh/authorized_keys + MaxAuthTries=3. Fixed by copying iMac key to root, bumping MaxAuthTries=6. Updated ssh_attack.py with key-based SSH fallback (no sshpass needed). Both FULL_SPECTRUM + FULL_COVERAGE_5X launched on iMac."
    },
    {
      "id": 19,
      "task": "Apply VirtualBox VM performance tweaks to all 5 VMs",
      "status": "completed",
      "priority": "medium",
      "note": "Applied by user. All 5 VMs running with tweaks."
    },
    {
      "id": 20,
      "task": "Fix sed quoting in FULL_SPECTRUM_CHAOS.sh Linux attacks",
      "status": "completed",
      "priority": "medium",
      "note": "Already fixed: ssh_attack.py uses the standard bash '\\'' escaping technique for single quotes in sudo wrapper. Both LIN-SSH-RootLogin and LIN-SSH-PasswordAuth sed attacks succeed in FULL_SPECTRUM test."
    },
    {
      "id": 21,
      "task": "Set static IP or DHCP reservation for appliance VM",
      "status": "pending",
      "priority": "medium",
      "note": "Appliance VM got DHCP .254 instead of expected .247 after reboot. Should set static IP in NixOS config or add DHCP reservation on router."
    },
    {
      "id": 17,
      "task": "Remove argparse bootstrap shim after nix rebuild",
      "status": "completed",
      "priority": "low",
      "note": "No action needed. The argparse.py shim was never included in production tarballs (package-agent.sh only copies compliance_agent/ source). Both appliances have the fixed _apply_overlay() via PYTHONPATH+os.execv (physical v1.0.64, VM v1.0.57)."
    },
    {
      "id": 22,
      "task": "Decouple Linux and Windows scan cycles into parallel async tasks",
      "status": "completed",
      "priority": "high",
      "note": "Replaced sequential awaits with asyncio.gather() in _run_cycle(). Linux+Windows+network+workstation scans now parallel. Cycle timeout increased 300\u2192600s."
    },
    {
      "id": 23,
      "task": "Add 6 Windows L1 rules + scan checks",
      "status": "completed",
      "priority": "medium",
      "note": "Added L1 rules: L1-WIN-SVC-DNS, L1-WIN-SEC-SMB, L1-WIN-SVC-WUAUSERV, L1-WIN-NET-PROFILE, L1-WIN-SEC-SCREENLOCK, L1-WIN-SEC-DEFENDER-EXCL. Added 5 new scan checks: smb_signing, service_wuauserv, network_profile, screen_lock_policy, defender_exclusions."
    },
    {
      "id": 24,
      "task": "Add L1 rules for 4 Linux checks",
      "status": "completed",
      "priority": "medium",
      "note": "Added L1-LIN-NET-001 (network), L1-LIN-BANNER-001 (banner), L1-LIN-CRYPTO-001 (crypto), L1-LIN-IR-001 (incident_response). All route to run_linux_runbook with existing runbook IDs."
    },
    {
      "id": 25,
      "task": "Fix flap tracker counting failed heals toward suppression",
      "status": "completed",
      "priority": "medium",
      "note": "Moved _track_flap() from before healing to after successful L1/L2 healing. Flap counter only increments on real resolve\u2192recur cycles. Added test_no_flap_without_successful_healing."
    },
    {
      "id": 26,
      "task": "Upload v1.0.65 overlay to VPS",
      "status": "completed",
      "priority": "low",
      "note": "Built overlay with all session 106 changes (L1 rules, flap fix, scan checks, parallel scans). Uploaded to root@178.156.162.116:/var/www/updates/agent-overlay.tar.gz"
    }
  ],
  "completed_this_session": [
    "Task #10: OTS expired proof background drain loop — _ots_resubmit_expired_loop() in main.py drains 78K expired proofs",
    "Task #17: Argparse shim confirmed not needed — both appliances have fixed _apply_overlay()",
    "Chaos test: 6 unhealed vectors diagnosed and patched",
    "Fixed L1-SUID-001 condition: match on runbook_id instead of non-existent details.suid_found",
    "Added L1-PERSIST-TASK-001 + L1-PERSIST-REG-001 rules (agent + server-side)",
    "Added ip_forward check to LIN-NET-001 detect/remediate/verify",
    "Fixed RB-WIN-NET-001 DNS remediation chicken-and-egg (DC IP fallback via nltest + gateway)",
    "Added check_type_map entries: scheduled_task_persistence, registry_run_persistence, dns_config",
    "Fixed server-side L1-LIN-SUID-001 to match runbook_id",
    "Prioritized healing in Linux drift processing — non-compliant l1_eligible items processed first",
    "Chaos test run 3: SRV-Task persistence HEALED (new rule), Audit HEALED, still hitting 600s cycle timeout for ip_forward/cron/SUID",
    "961 tests passing"
  ],
  "recent_commits": [
    {
      "hash": "83b6d22",
      "message": "fix: Prioritize healing in Linux drift processing to survive cycle timeout"
    },
    {
      "hash": "b65ef69",
      "message": "fix: Patch 6 unhealed chaos test vectors in auto-healing pipeline"
    },
    {
      "hash": "9bb32e1",
      "message": "fix: Include control_mappings.yaml in backend deploy for framework seeding"
    },
    {
      "hash": "3b1b1d4",
      "message": "fix: CVE Watch — use virtualMatchString for wildcard CPEs + 120-day initial window"
    },
    {
      "hash": "883b91b",
      "message": "feat: Compliance Library — live framework sync from official sources"
    }
  ],
  "key_findings": {
    "evidence_pipeline_status": "182,685 bundles in DB (111K physical, 71K test). Feb bundles all Ed25519 signed (2,408 signed). Hash chain 111K+ positions deep. Agent submits JSON to /api/evidence/sites/{site_id}/submit with Ed25519 signature + signed_data",
    "minio_worm_status": "evidence-worm-v2 bucket with COMPLIANCE 90d Object Lock. WORM uploads active (verified latest bundle in MinIO). Transient Docker DNS issue resolved after container restart",
    "compliance_packet_data": "Real HIPAA compliance packets LIVE at /api/evidence/sites/{site_id}/compliance-packet. Jan: 28.3% (109K bundles, early setup). Feb: 52.1% (2.4K bundles, all signed, 2.2K BTC-anchored). 15 check types mapped to HIPAA controls. MTTR 0.3-0.5h",
    "ots_status": "2,705 anchored to Bitcoin, 251 pending, 78,699 expired. Fixed construct_ots_file (missing version byte). Uses opentimestamps-client reference library. Upgrade loop: 15min/500 batch",
    "nix_overlay_lesson": "NixOS buildPythonApplication creates bash wrappers that override PYTHONPATH. os.execve re-runs the wrapper, losing the overlay. Fix: manipulate __path__ and sys.modules within the same process. For pre-fix appliances, hijack an import (argparse.py shim) to bootstrap the overlay.",
    "systemd_sandbox_lesson": "ProtectSystem=strict makes filesystem read-only. nixos-rebuild needs /nix/store write access. Use systemd-run --wait --pipe to escape the sandbox into an unsandboxed transient unit.",
    "deployment_lesson": "ALWAYS push to main instead of manual scp. CI/CD workflow (.github/workflows/deploy-central-command.yml) auto-deploys backend + frontend to VPS on push to main when mcp-server/central-command/** changes. Manual scp causes stale versions. Pipeline: checkout -> npm ci -> npm run build -> rsync backend to /opt/mcp-server/dashboard_api_mount/ -> rsync frontend to /opt/mcp-server/frontend_dist/ -> docker compose restart.",
    "learning_loop_stats_lesson": "Promotion history must match execution_telemetry by incident_type + hostname/site_id (from pattern_signature), NOT by runbook_id. Agent records executions with internal IDs (L1-SVC-DNS-001) that differ from promoted_to_rule_id (RB-AUTO-SERVICE_). The pattern_signature format is check_type:check_type:target where target is hostname or site_id.",
    "dashboard_asyncio_lesson": "SQLAlchemy AsyncSession cannot run concurrent queries via asyncio.gather(). Causes InvalidStateError. Must run queries sequentially on the same session. Fixed in db_queries.py, routes.py (2x), portal.py (1x). All deployed to VPS.",
    "l3_email_lesson": "L3 escalation emails are generated in email_alerts.py send_critical_alert(), called from main.py POST /incidents handler. The escalation_engine.py path (via notifications.py /api/escalations) is separate \u2014 used when agent posts to Central Command directly. Both paths now have rich context.",
    "phi_scrubber_lesson": "PHI scrubber in WindowsExecutor._execute_sync() replaces ALL IPs in WinRM output with [IP-REDACTED-xxx]. This breaks AD enumeration because IPv4Address values become unreachable hostnames. Fix: skip_phi_scrub=True parameter for infrastructure queries (AD enumeration, DNS resolution). PHI scrubber still active for all other WinRM queries (compliance checks, healing actions).",
    "flap_detector_lesson": "Flap detector thresholds must account for drift cooldown math. With 600s cooldown, max incidents in 30min = 3 (not 5). Three-layer fix needed: (1) agent-side flap thresholds 3/120min, (2) synced rules platform guard (rules from Central Command override built-in), (3) per-check cooldown extension to 1hr on flap. Synced rules at /var/lib/msp/rules/l1_rules.json override built-in rules in level1_deterministic.py \u2014 must update both.",
    "vbox_black_screen_lesson": "VirtualBox Ubuntu Server VMs show black screen on screenshotpng due to console blanking (screen saver). Fix: add consoleblank=0 to GRUB_CMDLINE_LINUX_DEFAULT. For best screenshot compatibility on server VMs, use vboxvga graphics controller. Also: use serial console (uart1 file mode) for headless debugging.",
    "linux_vm_ssh_lesson": "Ubuntu 24.04 server cloud-init can override sshd_config on boot. Fix: add /etc/cloud/cloud.cfg.d/99-disable-ssh-pwauth.cfg with ssh_pwauth:true. Also disable cloud-init networking via 99-disable-network-config.cfg to prevent netplan overrides. Password reset via NixOS live ISO: mount disk, chroot with explicit PATH=/usr/bin:/usr/sbin:/bin:/sbin, use chpasswd.",
    "vbox_scancode_lesson": "VBoxManage keyboardputscancode requires PS/2 keyboard mode (--keyboard ps2). USB keyboard mode breaks scancodes. Best approach for complex commands: boot NixOS live ISO, set nixos password + start sshd, SSH in for a real terminal. Helper script type_vm.sh converts ASCII to scancodes.",
    "ssh_auth_lesson": "When SSH agent has many keys, MaxAuthTries=3 causes 'Too many authentication failures' before the right key is tried. Fix: bump MaxAuthTries=6 AND ensure authorized_keys is populated for all users (root had empty file). ssh_attack.py now falls back to native SSH key auth when sshpass unavailable \u2014 uses BatchMode=yes with agent keys. Sudo commands wrap via echo password | sudo -S.",
    "appliance_dhcp_lesson": "Appliance VM DHCP lease can change after reboot (.247 -> .254). Serial console (uart1 file mode) is essential for diagnosing boot issues when network is unreachable. The appliance banner shows current IP on login prompt.",
    "ad_enrollment_lesson": "AD enumeration returns FQDNs (e.g., nvdc01.northvalley.local) that the appliance can't resolve because its DNS points to the router. Fix: resolve_missing_ips() runs bulk DNS lookup on the DC via PowerShell, then connectivity tests use IP-first (ip_address or fqdn or hostname). Direct TCP asyncio.open_connection() from appliance is faster and more accurate than PowerShell Test-NetConnection from DC.",
    "perf_audit_lesson": "Health endpoint was 2.18s because DB/Redis/MinIO checks ran sequentially and MinIO (sync SDK) blocked the event loop. Fix: asyncio.gather() + run_in_executor() for sync calls. N+1 in compliance scoring: each site triggered a separate query. Fix: ROW_NUMBER() window function in a single query. Redis caching (120s TTL) for expensive aggregates. Pre-computed reverse lookup dicts beat inner loops. Migration 039: pg_stat_user_indexes with idx_scan=0 identifies safe-to-drop indexes.",
    "overlay_structure_lesson": "Overlay tarball MUST preserve Python package structure: compliance_agent/ subdirectory required. Flat extraction (files at overlay root) means PYTHONPATH finds the overlay dir but 'from compliance_agent.X import Y' fails because there's no compliance_agent/ package. Previous overlay deployments appeared to work but were actually running NixOS store code \u2014 synced server-side L1 rules masked the issue.",
    "chaos_test_timing_lesson": "180s chaos test window is marginal for a full heal cycle. Even with parallel scans via asyncio.gather(), the 600s cycle timeout in _run_cycle() can abort the Linux drift processing loop before all drifts are healed. Root cause: drift results are processed sequentially (evidence submission + healing for each). SSH/FW/SVC healing consumes most of the budget, leaving NET/CRON/SUID unhealed. Fix applied: sort drift_results so non-compliant l1_eligible items are processed first (healing before evidence-only items). Remaining issue: ip_forward/cron/SUID still not healing in 180s window — likely need dedicated healing task queue that survives cycle boundaries.",
    "granular_flap_lesson": "Multiple runbooks sharing same check_type (e.g., SSH-001..004 all use ssh_config) cross-trigger flap detection because circuit_key = (site_id, host_id, incident_type). Fix: include runbook_id in flap key: flap_type = f'{incident_type}:{runbook_id}' when available. Also: _track_flap() counts ALL heal() calls regardless of success, so runbooks without L1 rules still increment flap counter and get permanently suppressed after 3 scan cycles."
  },
  "deployment_flow": [
    "1. Build installer ISO on VPS: nix build .#appliance-iso",
    "2. Write to USB: dd if=result/iso/*.iso of=/dev/diskN bs=4m",
    "3. Boot target hardware from USB",
    "4. msp-auto-install runs: dialog TUI with 8-step progress",
    "5. System reboots, compliance-agent calls home",
    "6. Central Command provisions via MAC address"
  ],
  "fleet_update_commands": {
    "deploy_overlay": "INSERT INTO admin_orders (order_id, appliance_id, site_id, order_type, parameters, status, expires_at) VALUES ('overlay-ID', 'APPLIANCE_ID', 'SITE_ID', 'update_agent', '{\"package_url\": \"https://api.osiriscare.net/agent-packages/compliance-agent-1.0.56.tar.gz\", \"version\": \"1.0.56-desc\"}', 'pending', now() + interval '2 hours')",
    "trigger_rebuild": "INSERT INTO admin_orders (order_id, appliance_id, site_id, order_type, parameters, status, expires_at) VALUES ('rebuild-ID', 'APPLIANCE_ID', 'SITE_ID', 'nixos_rebuild', '{\"flake_ref\": \"github:jbouey/msp-flake#osiriscare-appliance-disk\"}', 'pending', now() + interval '4 hours')",
    "run_diagnostic": "INSERT INTO admin_orders (order_id, appliance_id, site_id, order_type, parameters, status, expires_at) VALUES ('diag-ID', 'APPLIANCE_ID', 'SITE_ID', 'diagnostic', '{\"command\": \"agent_status\"}', 'pending', now() + interval '1 hour')",
    "appliance_ids": {
      "physical": "physical-appliance-pilot-1aea78-84:3A:5B:91:B6:61 (site: physical-appliance-pilot-1aea78)",
      "vm": "test-appliance-lab-b3c40c-08-00-27-98-FD-84 (site: test-appliance-lab-b3c40c)"
    }
  },
  "quick_commands": {
    "build_iso": "ssh root@178.156.162.116 'cd /opt/msp-flakes && nix build .#appliance-iso'",
    "vps_ssh": "ssh root@178.156.162.116",
    "imac_ssh": "ssh jrelly@192.168.88.50",
    "physical_ssh": "ssh jrelly@192.168.88.50 'ssh root@192.168.88.241'",
    "vm_rebuild": "ssh jrelly@192.168.88.50 \"ssh root@192.168.88.254 'nixos-rebuild test --flake github:jbouey/msp-flake#osiriscare-appliance-disk --refresh'\"  # NOTE: appliance VM currently at .254 (DHCP), may change",
    "physical_rebuild": "ssh jrelly@192.168.88.50 \"ssh root@192.168.88.241 'nixos-rebuild test --flake github:jbouey/msp-flake#osiriscare-appliance-disk --refresh'\"",
    "appliance_status": "ssh root@178.156.162.116 \"docker exec mcp-postgres psql -U mcp -d mcp -c 'SELECT site_id, agent_version, last_checkin FROM appliances ORDER BY last_checkin DESC'\"",
    "compliance_packet": "ssh root@178.156.162.116 \"curl -s 'http://localhost:8000/api/evidence/sites/physical-appliance-pilot-1aea78/compliance-packet?month=2&year=2026'\""
  },
  "context_files": {
    "credentials": ".agent/LAB_CREDENTIALS.md",
    "architecture": "docs/ARCHITECTURE.md",
    "phase_status": "IMPLEMENTATION-STATUS.md",
    "session_logs": ".agent/sessions/"
  }
}